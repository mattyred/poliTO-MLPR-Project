{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4e9e8754-a03f-480c-8417-0caada2b83ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.special\n",
    "import scipy.optimize\n",
    "import sklearn.datasets\n",
    "class LinearLogisticRegression:\n",
    "\n",
    "    def __init__(self, lbd, prior_weighted=False, prior=0.5):\n",
    "        self.lbd = lbd\n",
    "        self.prior_weighted = prior_weighted\n",
    "        self.prior = prior\n",
    "\n",
    "\n",
    "    def __compute_zi(self, ci):\n",
    "        return 2 * ci - 1\n",
    "\n",
    "    def __logreg_obj(self, v):\n",
    "        w, b = v[0:-1], v[-1]\n",
    "        z = 2 * self.Ltrain - 1\n",
    "        exp = (np.dot(w.T, self.Dtrain) + b)\n",
    "        reg = 0.5 * self.lbd * np.linalg.norm(w) ** 2\n",
    "        avg_risk = (np.logaddexp(0, -exp * z)).mean()\n",
    "        return reg + avg_risk\n",
    "\n",
    "    def __logreg_obj_prior_weighted(self, v):\n",
    "        w, b = v[0:-1], v[-1]\n",
    "        z = 2 * self.Ltrain - 1\n",
    "        reg = 0.5 * self.lbd * np.linalg.norm(w) ** 2\n",
    "        exp = (np.dot(w.T, self.Dtrain) + b)\n",
    "        avg_risk_0 = np.logaddexp(0, -exp[self.Ltrain == 0] * z[self.Ltrain == 0]).mean()*(1-self.prior)\n",
    "        avg_risk_1 = np.logaddexp(0, -exp[self.Ltrain == 1] * z[self.Ltrain == 1]).mean() * self.prior\n",
    "        return reg + avg_risk_0 + avg_risk_1\n",
    "    def train(self, Dtrain, Ltrain):\n",
    "        self.Dtrain = Dtrain\n",
    "        self.Ltrain = Ltrain\n",
    "        self.F = Dtrain.shape[0]  # dimensionality of features space\n",
    "        self.K = len(set(Ltrain))  # number of classes\n",
    "        self.N = Dtrain.shape[1]\n",
    "        obj_function = self.__logreg_obj if self.prior_weighted is False else self.__logreg_obj_prior_weighted\n",
    "        self.x, f, d = scipy.optimize.fmin_l_bfgs_b(func=obj_function,\n",
    "                                                    x0=np.zeros(self.Dtrain.shape[0] + 1),\n",
    "                                                    approx_grad=True,\n",
    "                                                    iprint=0)\n",
    "\n",
    "        \"\"\"                                            \n",
    "        print('Point of minimum: %s' % (self.x))\n",
    "        print('Value of the minimum: %s' % (f))\n",
    "        print('Number of iterations: %s' % (d['funcalls']))\n",
    "        \"\"\"\n",
    "        return self\n",
    "\n",
    "    def predict(self, Dtest, labels=True):\n",
    "        w, b = self.x[0:-1], self.x[-1]\n",
    "        S = np.zeros((Dtest.shape[1]))\n",
    "        for i in range(Dtest.shape[1]):\n",
    "            xi = Dtest[:, i:i + 1]\n",
    "            s = np.dot(w.T, xi) + b\n",
    "            S[i] = s\n",
    "        if labels:\n",
    "            LP = S > 0\n",
    "            return LP\n",
    "        else:\n",
    "            return S\n",
    "\n",
    "class QuadraticLogisticRegression:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __compute_zi(self, ci):\n",
    "        return 2 * ci - 1\n",
    "\n",
    "    def __logreg_obj(self, v):  # still works if DTR is one sample only? yes but it must be of shape (4,1)\n",
    "        w, b = v[0:-1], v[-1]\n",
    "        J = self.lbd / 2 * (np.linalg.norm(w) ** 2)\n",
    "        summary = 0\n",
    "        for i in range(self.N):\n",
    "            xi = self.Dtrain[:, i:i + 1]\n",
    "            ci = self.Ltrain[i]\n",
    "            zi = self.__compute_zi(ci)\n",
    "            summary += np.logaddexp(0, -zi * (np.dot(w.T, xi) + b))\n",
    "        J += (1 / self.N) * summary\n",
    "        return J\n",
    "\n",
    "    def train(self, Dtrain, Ltrain, lbd, maxiter):\n",
    "        self.Dtrain = Dtrain\n",
    "        self.Ltrain = Ltrain\n",
    "        self.lbd = lbd\n",
    "        self.maxiter = maxiter\n",
    "        self.F = Dtrain.shape[0]  # dimensionality of features space\n",
    "        self.K = len(set(Ltrain))  # number of classes\n",
    "        self.N = Dtrain.shape[1]\n",
    "        DTR_ext = numpy.hstack([self.__expandFeatures(self.Dtrain[:, i]) for i in range(self.Dtrain.shape[1])])\n",
    "        self.x, f, d = scipy.optimize.fmin_l_bfgs_b(func=self.__logreg_obj, \n",
    "                                                    x0=numpy.zeros(DTR_ext.shape[0] + 1), \n",
    "                                                    approx_grad = True, \n",
    "                                                    factr=1.0)\n",
    "        print('Point of minimum: %s' % (self.x))\n",
    "        print('Value of the minimum: %s' % (f))\n",
    "        print('Number of iterations: %s' % (d['funcalls']))\n",
    "        return self    \n",
    "    \n",
    "    def __expandFeatures(x):\n",
    "        x = utils.mcol(x)\n",
    "        expX = utils.mcol(numpy.dot(x, x.T))\n",
    "        return numpy.vstack([expX, x])\n",
    "\n",
    "    def predict(self, Dtest):\n",
    "        DTE_ext = numpy.hstack([self.__expandFeatures(Dtest[:, i]) for i in range(Dtest.shape[1])])\n",
    "        w, b = utils.mcol(self.x[0:-1]), self.x[-1]\n",
    "        scores = numpy.dot(w.T, DTE_ext) + b\n",
    "        return scores[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "52a299b5-d1e4-4cc4-b2da-2b75c6cda2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_iris_binary():\n",
    "    D, L = sklearn.datasets.load_iris()['data'].T, sklearn.datasets.load_iris()['target']\n",
    "    D = D[:, L != 0] # remove setosa from D\n",
    "    L = L[L!=0] # remove setosa from L\n",
    "    L[L==2] = 0 # We assign label 0 to virginica (was label 2)\n",
    "    return D, L\n",
    "def load_iris():\n",
    "    D, L = sklearn.datasets.load_iris()['data'].T, sklearn.datasets.load_iris()['target']\n",
    "    return D, L\n",
    "def split_db_2to1(D, L, seed=0):\n",
    "    nTrain = int(D.shape[1]*2.0/3.0) # 2/3 of the dataset D are used for training, 1/3 for validation\n",
    "    np.random.seed(seed)\n",
    "    idx = np.random.permutation(D.shape[1]) # take a random array of 150 elements, each element is 0<x<=149 (np.arange(150))\n",
    "    idxTrain = idx[0:nTrain] # first 100 are indices of training samples\n",
    "    idxTest = idx[nTrain:] # remaining 50 are indices of validation samples\n",
    "    DTR = D[:, idxTrain] # D for training\n",
    "    DTE = D[:, idxTest] # D for validation\n",
    "    LTR = L[idxTrain] # L for training\n",
    "    LTE = L[idxTest] # L for validation\n",
    "    return (DTR, LTR), (DTE, LTE)\n",
    "\n",
    "DT, LT = load_iris()\n",
    "(DTR, LTR), (DTE, LTE) = split_db_2to1(DT, LT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0c916d38-fef2-4069-9f40-7441a1a37198",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    def __init__(self, hparams, kernel=None):\n",
    "        self.kernelType = kernel\n",
    "        self.C = hparams['C']\n",
    "        self.K = hparams['K']\n",
    "        self.eps = hparams.get('eps')\n",
    "        self.gamma = hparams.get('gamma')\n",
    "        self.c = hparams.get('c')\n",
    "        self.d = hparams.get('d')\n",
    "\n",
    "    def __LDc_obj(self, alpha):\n",
    "        #grad = np.dot(self.H, alpha) - np.ones(self.H.shape[1])\n",
    "        t = 0.5 * np.dot(np.dot(alpha.reshape(1, -1), self.H), alpha) - alpha.sum(), np.dot(self.H, alpha) - 1\n",
    "        return t\n",
    "\n",
    "    def __polynomial_kernel(self, X1, X2):\n",
    "        ker = (np.dot(X1.T, X2) + self.c) ** self.d + self.K ** 2\n",
    "        return ker\n",
    "\n",
    "    def __RBF_kernel(self, X1, X2):\n",
    "        x = np.repeat(X1, X2.shape[1], axis=1)\n",
    "        y = np.tile(X2, X1.shape[1])\n",
    "        ker = np.exp(\n",
    "            -self.gamma * np.linalg.norm(x - y, axis=0).reshape(X1.shape[1], X2.shape[1]) ** 2) + self.K ** 2\n",
    "        return ker\n",
    "\n",
    "    def train(self, Dtrain, Ltrain):\n",
    "        self.Dtrain = Dtrain\n",
    "        self.Ltrain = Ltrain\n",
    "        self.N = Dtrain.shape[1]\n",
    "        self.Ltrain_z = self.Ltrain * 2 - 1\n",
    "        self.Ltrain_z_matrix = self.Ltrain_z.reshape(-1, 1) * self.Ltrain_z.reshape(1, -1)\n",
    "        self.bounds = np.array([(0, self.C)] * Ltrain.shape[0])\n",
    "\n",
    "        if self.kernelType is not None:\n",
    "            if self.kernelType == 'Polynomial':\n",
    "                ker = self.__polynomial_kernel(self.Dtrain, self.Dtrain)\n",
    "            elif self.kernelType == 'RBF':\n",
    "                ker = self.__RBF_kernel(self.Dtrain, self.Dtrain)\n",
    "            else:\n",
    "                return\n",
    "            self.H = self.Ltrain_z_matrix * ker\n",
    "        else:\n",
    "            # Compute expanded D matrix\n",
    "            self.expandedD = np.vstack((Dtrain, self.K * np.ones(self.N)))\n",
    "            # Compute H matrix\n",
    "            G = np.dot(self.expandedD.T, self.expandedD)\n",
    "            self.H = G * self.Ltrain_z_matrix\n",
    "\n",
    "        self.alpha, self.primal, _ = scipy.optimize.fmin_l_bfgs_b(func=self.__LDc_obj,\n",
    "                                                                    bounds=self.bounds,\n",
    "                                                                    x0=np.zeros(Dtrain.shape[1]),\n",
    "                                                                    factr=1.0,\n",
    "                                                                     maxfun=5000,\n",
    "                                                                     maxiter=5000)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, Dtest, labels=False):\n",
    "        if self.kernelType is not None:\n",
    "            if self.kernelType == 'Polynomial':\n",
    "                self.S = np.sum(np.dot((self.alpha * self.Ltrain_z).reshape(1, -1), self.__polynomial_kernel(self.Dtrain, Dtest)), axis=0)\n",
    "            elif self.kernelType == 'RBF':\n",
    "                self.S = np.sum(np.dot((self.alpha * self.Ltrain_z).reshape(1, -1), self.__RBF_kernel(self.Dtrain, Dtest)), axis=0)\n",
    "            else:\n",
    "                return\n",
    "        else:\n",
    "            wc = np.sum(self.alpha * self.Ltrain_z * self.expandedD, axis=1)\n",
    "            self.w, self.b = wc[:-1], wc[-1::]\n",
    "            self.S = np.dot(self.w.T, Dtest) + self.b * self.K\n",
    "\n",
    "        if labels is True:\n",
    "            predicted_labels = np.where(self.S > 0, 1, 0)\n",
    "            return predicted_labels\n",
    "        else:\n",
    "            return self.S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "87d9a8f9-0100-4c99-b0a7-cf3d0af81394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_training(path):\n",
    "    DT = np.zeros(shape=(12, 6000), dtype='float32')  # DT: Data Training\n",
    "    LT = np.zeros(6000, dtype='int32')  # LT: Labels Training\n",
    "    with open(path, 'r') as file:\n",
    "        i = 0\n",
    "        for line in file:\n",
    "            features_list = line.split(',')\n",
    "            features = np.array(features_list[0:12], dtype='float32').reshape(-1, 1)\n",
    "            label = int(features_list[-1])\n",
    "            DT[:, i:i + 1] = features\n",
    "            LT[i] = label\n",
    "            i += 1\n",
    "    return DT, LT\n",
    "\n",
    "def read_data_evaluation(path):\n",
    "    DE = np.zeros(shape=(12, 4000), dtype='float32')  # DT: Data Training\n",
    "    LE = np.zeros(4000, dtype='int32')  # LT: Labels Training\n",
    "    with open(path, 'r') as file:\n",
    "        i = 0\n",
    "        for line in file:\n",
    "            features_list = line.split(',')\n",
    "            features = np.array(features_list[0:12], dtype='float32').reshape(-1, 1)\n",
    "            label = int(features_list[-1])\n",
    "            DE[:, i:i + 1] = features\n",
    "            LE[i] = label\n",
    "            i += 1\n",
    "    return DE, LE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5c1254ab-3eca-4298-b7c7-5dd71d15f3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DT, LT = read_data_training('Train.txt')\n",
    "#DE, LE = read_data_evaluation('Test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8fc0217e-7f07-4612-9ceb-9dae00684aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.special\n",
    "\n",
    "\n",
    "class GMM:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def logpdf_GAU_ND(self, X, mu, C):\n",
    "        invC = np.linalg.inv(C)\n",
    "        _, log_abs_detC = np.linalg.slogdet(C)\n",
    "        M = X.shape[0]\n",
    "        return - M/2 * np.log(2 * np.pi) - 0.5 * log_abs_detC - 0.5 * ((X - mu) * np.dot(invC, X - mu)).sum(0)\n",
    "\n",
    "    def logpdf_GMM(self, X, gmm):\n",
    "        S = np.zeros((len(gmm), X.shape[1]))\n",
    "\n",
    "        for g in range(len(gmm)):\n",
    "            (w, mu, C) = gmm[g]\n",
    "            S[g, :] = self.logpdf_GAU_ND(X, mu, C) + np.log(w)\n",
    "\n",
    "        logdens = scipy.special.logsumexp(S, axis=0)\n",
    "        return S, logdens\n",
    "\n",
    "    def GMM_algorithm_EM(self, X, gmm, psi=0.01, cov='Full'):\n",
    "        thNew = None\n",
    "        thOld = None\n",
    "        N = X.shape[1]\n",
    "        D = X.shape[0]\n",
    "\n",
    "        while thOld == None or thNew - thOld > 1e-6:\n",
    "            thOld = thNew\n",
    "            logSj, logSjMarg = self.logpdf_GMM(X, gmm)\n",
    "            thNew = np.sum(logSjMarg) / N\n",
    "\n",
    "            P = np.exp(logSj - logSjMarg)\n",
    "\n",
    "            if cov == 'Diag':\n",
    "                newGmm = []\n",
    "                for i in range(len(gmm)):\n",
    "                    gamma = P[i, :]\n",
    "                    Z = gamma.sum()\n",
    "                    F = (gamma.reshape(1, -1) * X).sum(1)\n",
    "                    S = np.dot(X, (gamma.reshape(1, -1) * X).T)\n",
    "                    w = Z / N\n",
    "                    mu = (F / Z).reshape(-1, 1)\n",
    "                    sigma = S / Z - np.dot(mu, mu.T)\n",
    "                    sigma *= np.eye(sigma.shape[0])\n",
    "                    U, s, _ = np.linalg.svd(sigma)\n",
    "                    s[s < psi] = psi\n",
    "                    sigma = np.dot(U, s.reshape(-1, 1) * U.T)\n",
    "                    newGmm.append((w, mu, sigma))\n",
    "                gmm = newGmm\n",
    "\n",
    "            elif cov == 'Tied':\n",
    "                newGmm = []\n",
    "                sigmaTied = np.zeros((D, D))\n",
    "                for i in range(len(gmm)):\n",
    "                    gamma = P[i, :]\n",
    "                    Z = gamma.sum()\n",
    "                    F = (gamma.reshape(1, -1) * X).sum(1)\n",
    "                    S = np.dot(X, (gamma.reshape(1, -1) * X).T)\n",
    "                    w = Z / N\n",
    "                    mu = (F / Z).reshape(-1, 1)\n",
    "                    sigma = S / Z - np.dot(mu, mu.T)\n",
    "                    sigmaTied += Z * sigma\n",
    "                    newGmm.append((w, mu))\n",
    "                gmm = newGmm\n",
    "                sigmaTied /= N\n",
    "                U, s, _ = np.linalg.svd(sigmaTied)\n",
    "                s[s < psi] = psi\n",
    "                sigmaTied = np.dot(U, s.reshape(-1, 1) * U.T)\n",
    "\n",
    "                newGmm = []\n",
    "                for i in range(len(gmm)):\n",
    "                    (w, mu) = gmm[i]\n",
    "                    newGmm.append((w, mu, sigmaTied))\n",
    "\n",
    "                gmm = newGmm\n",
    "\n",
    "            elif cov == 'TiedDiag':\n",
    "                newGmm = []\n",
    "                sigmaTied = np.zeros((D, D))\n",
    "                for i in range(len(gmm)):\n",
    "                    gamma = P[i, :]\n",
    "                    Z = gamma.sum()\n",
    "                    F = (gamma.reshape(1, -1) * X).sum(1)\n",
    "                    S = np.dot(X, (gamma.reshape(1, -1) * X).T)\n",
    "                    w = Z / N\n",
    "                    mu = (F / Z).reshape(-1, 1)\n",
    "                    sigma = S / Z - np.dot(mu, mu.T)\n",
    "                    sigmaTied += Z * sigma\n",
    "                    newGmm.append((w, mu))\n",
    "                gmm = newGmm\n",
    "                sigmaTied /= N\n",
    "                sigmaTied *= np.eye(sigma.shape[0])\n",
    "                U, s, _ = np.linalg.svd(sigmaTied)\n",
    "                s[s < psi] = psi\n",
    "                sigmaTied = np.dot(U, s.reshape(-1, 1) * U.T)\n",
    "\n",
    "                newGmm = []\n",
    "                for i in range(len(gmm)):\n",
    "                    (w, mu) = gmm[i]\n",
    "                    newGmm.append((w, mu, sigmaTied))\n",
    "\n",
    "                gmm = newGmm\n",
    "\n",
    "            else:\n",
    "                newGmm = []\n",
    "                for i in range(len(gmm)):\n",
    "                    gamma = P[i, :]\n",
    "                    Z = gamma.sum()\n",
    "                    F = (gamma.reshape(1, -1) * X).sum(1)\n",
    "                    S = np.dot(X, (gamma.reshape(1, -1) * X).T)\n",
    "                    w = Z / N\n",
    "                    mu = (F / Z).reshape(-1, 1)\n",
    "                    sigma = S / Z - np.dot(mu, mu.T)\n",
    "                    U, s, _ = np.linalg.svd(sigma)\n",
    "                    s[s < psi] = psi\n",
    "                    sigma = np.dot(U, s.reshape(-1, 1) * U.T)\n",
    "                    newGmm.append((w, mu, sigma))\n",
    "                gmm = newGmm\n",
    "        return gmm\n",
    "\n",
    "    def GMM_algorithm_LBG(self, X, alpha, nComponents, psi=0.01, covType='Full'):\n",
    "        mean = X.mean(axis=1).reshape(-1, 1)\n",
    "        cov = 1 / X.shape[1] * np.dot(X - mean, (X - mean).T)\n",
    "        gmm = [(1, mean, cov)]\n",
    "\n",
    "        while len(gmm) <= nComponents:\n",
    "            gmm = self.GMM_algorithm_EM(X, gmm, psi, covType)\n",
    "\n",
    "            if len(gmm) == nComponents:\n",
    "                break\n",
    "\n",
    "            newGmm = []\n",
    "            for i in range(len(gmm)):\n",
    "                (w, mu, sigma) = gmm[i]\n",
    "                U, s, Vh = np.linalg.svd(sigma)\n",
    "                d = U[:, 0:1] * s[0] ** 0.5 * alpha\n",
    "                newGmm.append((w / 2, mu + d, sigma))\n",
    "                newGmm.append((w / 2, mu - d, sigma))\n",
    "            gmm = newGmm\n",
    "\n",
    "        return gmm\n",
    "\n",
    "    def trainGMM(self, DTR, LTR, DTE, alpha, nComponents, psi=0.01, covType='Full'):\n",
    "        DTR_0 = DTR[:, LTR == 0]\n",
    "        gmm_c0 = self.GMM_algorithm_LBG(DTR_0, alpha, nComponents, psi, covType)\n",
    "        _, llr_0 = self.logpdf_GMM(DTE, gmm_c0)\n",
    "\n",
    "        DTR_1 = DTR[:, LTR == 1]\n",
    "        gmm_c1 = self.GMM_algorithm_LBG(DTR_1, alpha, nComponents, psi, covType)\n",
    "        _, llr_1 = self.logpdf_GMM(DTE, gmm_c1)\n",
    "\n",
    "        return llr_1 - llr_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d02ad441-c11f-49da-ab3e-dee5b7d78b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = GMM()\n",
    "alpha=0.1\n",
    "nComponents = 4\n",
    "psi = 0.01\n",
    "covType='Diag'\n",
    "gmm_c0 = g.GMM_algorithm_LBG(DTR[:, LTR==0], alpha, nComponents, psi, covType)\n",
    "_, llr_0 = g.logpdf_GMM(DTE, gmm_c0)\n",
    "gmm_c1 = g.GMM_algorithm_LBG(DTR[:, LTR==1], alpha, nComponents, psi, covType)\n",
    "_, llr_1 = g.logpdf_GMM(DTE, gmm_c1)\n",
    "gmm_c2 = g.GMM_algorithm_LBG(DTR[:, LTR==2], alpha, nComponents, psi, covType)\n",
    "_, llr_2 = g.logpdf_GMM(DTE, gmm_c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e8f255f3-d9e2-498f-a197-b537d7c0e070",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = np.vstack([llr_0.reshape(1, -1), llr_1.reshape(1, -1), llr_2.reshape(1, -1)])\n",
    "predicted = np.argmax(S, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a85b6922-faca-4846-8d6d-401bd5dafbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate:  6.000000000000005 %%\n"
     ]
    }
   ],
   "source": [
    "print('Error rate: ', (1-sum(predicted == LTE)/len(LTE))*100,'%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e318c37-00b3-4a7f-bfff-249fa677227c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

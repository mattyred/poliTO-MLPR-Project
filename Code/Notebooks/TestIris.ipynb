{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e9e8754-a03f-480c-8417-0caada2b83ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.special\n",
    "import scipy.optimize\n",
    "import sklearn.datasets\n",
    "class LinearLogisticRegression:\n",
    "\n",
    "    def __init__(self, lbd, prior_weighted=False, prior=0.5):\n",
    "        self.lbd = lbd\n",
    "        self.prior_weighted = prior_weighted\n",
    "        self.prior = prior\n",
    "\n",
    "\n",
    "    def __compute_zi(self, ci):\n",
    "        return 2 * ci - 1\n",
    "\n",
    "    def __logreg_obj(self, v):\n",
    "        w, b = v[0:-1], v[-1]\n",
    "        z = 2 * self.Ltrain - 1\n",
    "        exp = (np.dot(w.T, self.Dtrain) + b)\n",
    "        reg = 0.5 * self.lbd * np.linalg.norm(w) ** 2\n",
    "        avg_risk = (np.logaddexp(0, -exp * z)).mean()\n",
    "        return reg + avg_risk\n",
    "\n",
    "    def __logreg_obj_prior_weighted(self, v):\n",
    "        w, b = v[0:-1], v[-1]\n",
    "        z = 2 * self.Ltrain - 1\n",
    "        reg = 0.5 * self.lbd * np.linalg.norm(w) ** 2\n",
    "        exp = (np.dot(w.T, self.Dtrain) + b)\n",
    "        avg_risk_0 = np.logaddexp(0, -exp[self.Ltrain == 0] * z[self.Ltrain == 0]).mean()*(1-self.prior)\n",
    "        avg_risk_1 = np.logaddexp(0, -exp[self.Ltrain == 1] * z[self.Ltrain == 1]).mean() * self.prior\n",
    "        return reg + avg_risk_0 + avg_risk_1\n",
    "    def train(self, Dtrain, Ltrain):\n",
    "        self.Dtrain = Dtrain\n",
    "        self.Ltrain = Ltrain\n",
    "        self.F = Dtrain.shape[0]  # dimensionality of features space\n",
    "        self.K = len(set(Ltrain))  # number of classes\n",
    "        self.N = Dtrain.shape[1]\n",
    "        obj_function = self.__logreg_obj if self.prior_weighted is False else self.__logreg_obj_prior_weighted\n",
    "        self.x, f, d = scipy.optimize.fmin_l_bfgs_b(func=obj_function,\n",
    "                                                    x0=np.zeros(self.Dtrain.shape[0] + 1),\n",
    "                                                    approx_grad=True,\n",
    "                                                    iprint=0)\n",
    "\n",
    "        \"\"\"                                            \n",
    "        print('Point of minimum: %s' % (self.x))\n",
    "        print('Value of the minimum: %s' % (f))\n",
    "        print('Number of iterations: %s' % (d['funcalls']))\n",
    "        \"\"\"\n",
    "        return self\n",
    "\n",
    "    def predict(self, Dtest, labels=True):\n",
    "        w, b = self.x[0:-1], self.x[-1]\n",
    "        S = np.zeros((Dtest.shape[1]))\n",
    "        for i in range(Dtest.shape[1]):\n",
    "            xi = Dtest[:, i:i + 1]\n",
    "            s = np.dot(w.T, xi) + b\n",
    "            S[i] = s\n",
    "        if labels:\n",
    "            LP = S > 0\n",
    "            return LP\n",
    "        else:\n",
    "            return S\n",
    "\n",
    "class QuadraticLogisticRegression:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __compute_zi(self, ci):\n",
    "        return 2 * ci - 1\n",
    "\n",
    "    def __logreg_obj(self, v):  # still works if DTR is one sample only? yes but it must be of shape (4,1)\n",
    "        w, b = v[0:-1], v[-1]\n",
    "        J = self.lbd / 2 * (np.linalg.norm(w) ** 2)\n",
    "        summary = 0\n",
    "        for i in range(self.N):\n",
    "            xi = self.Dtrain[:, i:i + 1]\n",
    "            ci = self.Ltrain[i]\n",
    "            zi = self.__compute_zi(ci)\n",
    "            summary += np.logaddexp(0, -zi * (np.dot(w.T, xi) + b))\n",
    "        J += (1 / self.N) * summary\n",
    "        return J\n",
    "\n",
    "    def train(self, Dtrain, Ltrain, lbd, maxiter):\n",
    "        self.Dtrain = Dtrain\n",
    "        self.Ltrain = Ltrain\n",
    "        self.lbd = lbd\n",
    "        self.maxiter = maxiter\n",
    "        self.F = Dtrain.shape[0]  # dimensionality of features space\n",
    "        self.K = len(set(Ltrain))  # number of classes\n",
    "        self.N = Dtrain.shape[1]\n",
    "        DTR_ext = numpy.hstack([self.__expandFeatures(self.Dtrain[:, i]) for i in range(self.Dtrain.shape[1])])\n",
    "        self.x, f, d = scipy.optimize.fmin_l_bfgs_b(func=self.__logreg_obj, \n",
    "                                                    x0=numpy.zeros(DTR_ext.shape[0] + 1), \n",
    "                                                    approx_grad = True, \n",
    "                                                    factr=1.0)\n",
    "        print('Point of minimum: %s' % (self.x))\n",
    "        print('Value of the minimum: %s' % (f))\n",
    "        print('Number of iterations: %s' % (d['funcalls']))\n",
    "        return self    \n",
    "    \n",
    "    def __expandFeatures(x):\n",
    "        x = utils.mcol(x)\n",
    "        expX = utils.mcol(numpy.dot(x, x.T))\n",
    "        return numpy.vstack([expX, x])\n",
    "\n",
    "    def predict(self, Dtest):\n",
    "        DTE_ext = numpy.hstack([self.__expandFeatures(Dtest[:, i]) for i in range(Dtest.shape[1])])\n",
    "        w, b = utils.mcol(self.x[0:-1]), self.x[-1]\n",
    "        scores = numpy.dot(w.T, DTE_ext) + b\n",
    "        return scores[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52a299b5-d1e4-4cc4-b2da-2b75c6cda2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_iris_binary():\n",
    "    D, L = sklearn.datasets.load_iris()['data'].T, sklearn.datasets.load_iris()['target']\n",
    "    D = D[:, L != 0] # remove setosa from D\n",
    "    L = L[L!=0] # remove setosa from L\n",
    "    L[L==2] = 0 # We assign label 0 to virginica (was label 2)\n",
    "    return D, L\n",
    "def split_db_2to1(D, L, seed=0):\n",
    "    nTrain = int(D.shape[1]*2.0/3.0) # 2/3 of the dataset D are used for training, 1/3 for validation\n",
    "    np.random.seed(seed)\n",
    "    idx = np.random.permutation(D.shape[1]) # take a random array of 150 elements, each element is 0<x<=149 (np.arange(150))\n",
    "    idxTrain = idx[0:nTrain] # first 100 are indices of training samples\n",
    "    idxTest = idx[nTrain:] # remaining 50 are indices of validation samples\n",
    "    DTR = D[:, idxTrain] # D for training\n",
    "    DTE = D[:, idxTest] # D for validation\n",
    "    LTR = L[idxTrain] # L for training\n",
    "    LTE = L[idxTest] # L for validation\n",
    "    return (DTR, LTR), (DTE, LTE)\n",
    "\n",
    "DT, LT = load_iris_binary()\n",
    "(DTR, LTR), (DTE, LTE) = split_db_2to1(DT, LT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4c549cd-dd38-4bc5-a8a5-77cc4ad876c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate:  8.823529411764708\n"
     ]
    }
   ],
   "source": [
    "lbd = 10**-3\n",
    "maxiter=100\n",
    "model = LinearLogisticRegression(lbd, prior_weighted=True, prior=0.5)\n",
    "labs = model.train(DTR, LTR).predict(DTE, labels=True)\n",
    "print('Error rate: ', (1 - (sum(labs == LTE) / len(LTE))) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b70261e-33fd-45bf-9b14-e9a5286e912f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'numpy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/48/1_svc68j0_b2js686ls_zqhh0000gn/T/ipykernel_4462/4154241954.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQuadraticLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlabs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDTR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLTR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlbd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDTE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Error rate: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mLTE\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLTE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/48/1_svc68j0_b2js686ls_zqhh0000gn/T/ipykernel_4462/2370819346.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, Dtrain, Ltrain, lbd, maxiter)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# number of classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mDTR_ext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__expandFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         self.x, f, d = scipy.optimize.fmin_l_bfgs_b(func=self.__logreg_obj, \n\u001b[1;32m     93\u001b[0m                                                     \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDTR_ext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'numpy' is not defined"
     ]
    }
   ],
   "source": [
    "lbd = 10**-3\n",
    "maxiter=100\n",
    "model = QuadraticLogisticRegression()\n",
    "labs = model.train(DTR, LTR, lbd, maxiter).predict(DTE, labels=True)\n",
    "print('Error rate: ', 1 - (sum(labs == LTE) / len(LTE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c916d38-fef2-4069-9f40-7441a1a37198",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    def __init__(self, hparams, kernel=None):\n",
    "        self.kernelType = kernel\n",
    "        self.C = hparams['C']\n",
    "        self.K = hparams['K']\n",
    "        self.eps = hparams.get('eps')\n",
    "        self.gamma = hparams.get('gamma')\n",
    "        self.c = hparams.get('c')\n",
    "        self.d = hparams.get('d')\n",
    "\n",
    "    def __LDc_obj(self, alpha):\n",
    "        #grad = np.dot(self.H, alpha) - np.ones(self.H.shape[1])\n",
    "        t = 0.5 * np.dot(np.dot(alpha.reshape(1, -1), self.H), alpha) - alpha.sum(), np.dot(self.H, alpha) - 1\n",
    "        return t\n",
    "\n",
    "    def __polynomial_kernel(self, X1, X2):\n",
    "        ker = (np.dot(X1.T, X2) + self.c) ** self.d + self.K ** 2\n",
    "        return ker\n",
    "\n",
    "    def __RBF_kernel(self, X1, X2):\n",
    "        x = np.repeat(X1, X2.shape[1], axis=1)\n",
    "        y = np.tile(X2, X1.shape[1])\n",
    "        ker = np.exp(\n",
    "            -self.gamma * np.linalg.norm(x - y, axis=0).reshape(X1.shape[1], X2.shape[1]) ** 2) + self.K ** 2\n",
    "        return ker\n",
    "\n",
    "    def train(self, Dtrain, Ltrain):\n",
    "        self.Dtrain = Dtrain\n",
    "        self.Ltrain = Ltrain\n",
    "        self.N = Dtrain.shape[1]\n",
    "        self.Ltrain_z = self.Ltrain * 2 - 1\n",
    "        self.Ltrain_z_matrix = self.Ltrain_z.reshape(-1, 1) * self.Ltrain_z.reshape(1, -1)\n",
    "        self.bounds = np.array([(0, self.C)] * Ltrain.shape[0])\n",
    "\n",
    "        if self.kernelType is not None:\n",
    "            if self.kernelType == 'Polynomial':\n",
    "                ker = self.__polynomial_kernel(self.Dtrain, self.Dtrain)\n",
    "            elif self.kernelType == 'RBF':\n",
    "                ker = self.__RBF_kernel(self.Dtrain, self.Dtrain)\n",
    "            else:\n",
    "                return\n",
    "            self.H = self.Ltrain_z_matrix * ker\n",
    "        else:\n",
    "            # Compute expanded D matrix\n",
    "            self.expandedD = np.vstack((Dtrain, self.K * np.ones(self.N)))\n",
    "            # Compute H matrix\n",
    "            G = np.dot(self.expandedD.T, self.expandedD)\n",
    "            self.H = G * self.Ltrain_z_matrix\n",
    "\n",
    "        self.alpha, self.primal, _ = scipy.optimize.fmin_l_bfgs_b(func=self.__LDc_obj,\n",
    "                                                                    bounds=self.bounds,\n",
    "                                                                    x0=np.zeros(Dtrain.shape[1]),\n",
    "                                                                    factr=1.0,\n",
    "                                                                     maxfun=5000,\n",
    "                                                                     maxiter=5000)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, Dtest, labels=False):\n",
    "        if self.kernelType is not None:\n",
    "            if self.kernelType == 'Polynomial':\n",
    "                self.S = np.sum(np.dot((self.alpha * self.Ltrain_z).reshape(1, -1), self.__polynomial_kernel(self.Dtrain, Dtest)), axis=0)\n",
    "            elif self.kernelType == 'RBF':\n",
    "                self.S = np.sum(np.dot((self.alpha * self.Ltrain_z).reshape(1, -1), self.__RBF_kernel(self.Dtrain, Dtest)), axis=0)\n",
    "            else:\n",
    "                return\n",
    "        else:\n",
    "            wc = np.sum(self.alpha * self.Ltrain_z * self.expandedD, axis=1)\n",
    "            self.w, self.b = wc[:-1], wc[-1::]\n",
    "            self.S = np.dot(self.w.T, Dtest) + self.b * self.K\n",
    "\n",
    "        if labels is True:\n",
    "            predicted_labels = np.where(self.S > 0, 1, 0)\n",
    "            return predicted_labels\n",
    "        else:\n",
    "            return self.S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "13e2de83-3348-46a3-8615-9fdb46e53aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {'K': 0, 'eps': 0, 'gamma': 1, 'C': 1, 'c': 0, 'd': 2}\n",
    "svm = SVM(hparams, kernel='Polynomial')\n",
    "scores = svm.train(DTR, LTR).predict(DTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e974e284-27c7-40e1-9c07-416df817f9fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.823529411764708"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_labels = np.where(scores > 0, 1, 0)\n",
    "acc = sum(predict_labels == LTE) / len(predict_labels)\n",
    "(1-acc)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4723a4ae-db57-4ba9-9f34-80dd94458431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05882352941176472"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(DTR.T, LTR)\n",
    "1-sum(clf.predict(DTE.T)==LTE)/len(LTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e8267533-255d-45d0-bf9f-0330d48c1ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.882352941176472"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='poly', degree=2, coef0=0, C=1)\n",
    "clf.fit(DTR.T, LTR)\n",
    "(1-sum(clf.predict(DTE.T)==LTE)/len(LTE))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a1e2fdf4-ed0f-4c4b-8845-6f7b4d9e7f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.823529411764708"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='rbf', gamma=11)\n",
    "clf.fit(DTR.T, LTR)\n",
    "(1-sum(clf.predict(DTE.T)==LTE)/len(LTE))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "87d9a8f9-0100-4c99-b0a7-cf3d0af81394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_training(path):\n",
    "    DT = np.zeros(shape=(12, 6000), dtype='float32')  # DT: Data Training\n",
    "    LT = np.zeros(6000, dtype='int32')  # LT: Labels Training\n",
    "    with open(path, 'r') as file:\n",
    "        i = 0\n",
    "        for line in file:\n",
    "            features_list = line.split(',')\n",
    "            features = np.array(features_list[0:12], dtype='float32').reshape(-1, 1)\n",
    "            label = int(features_list[-1])\n",
    "            DT[:, i:i + 1] = features\n",
    "            LT[i] = label\n",
    "            i += 1\n",
    "    return DT, LT\n",
    "\n",
    "def read_data_evaluation(path):\n",
    "    DE = np.zeros(shape=(12, 4000), dtype='float32')  # DT: Data Training\n",
    "    LE = np.zeros(4000, dtype='int32')  # LT: Labels Training\n",
    "    with open(path, 'r') as file:\n",
    "        i = 0\n",
    "        for line in file:\n",
    "            features_list = line.split(',')\n",
    "            features = np.array(features_list[0:12], dtype='float32').reshape(-1, 1)\n",
    "            label = int(features_list[-1])\n",
    "            DE[:, i:i + 1] = features\n",
    "            LE[i] = label\n",
    "            i += 1\n",
    "    return DE, LE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5c1254ab-3eca-4298-b7c7-5dd71d15f3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT, LT = read_data_training('Train.txt')\n",
    "DE, LE = read_data_evaluation('Test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494f7809-8690-439b-9559-28b69081ec6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {'K': 0, 'eps': 0, 'gamma': 1, 'C': 1, 'c': 1, 'd': 2}\n",
    "svm = SVM(hparams, kernel='Polynomial')\n",
    "scores = svm.train(DT, LT).predict(DE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "03a305d6-1025-46da-898d-f617b06a20bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = scores > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f2ba3d59-437f-4a86-8f0c-719f2f27c86b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58175"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pred==LE)/len(LE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc0217e-7f07-4612-9ceb-9dae00684aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
